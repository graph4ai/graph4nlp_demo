{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAAI'22 Graph4NLP Tutorial Demo: Math Word Problem\n",
    "\n",
    "---\n",
    "\n",
    "### Introduction\n",
    "In this demo, we will have a closer look at how to apply **Graph2Tree model to the task of math word problem automatically solving**.\n",
    "Math word problem solving aims to infer reasonable equations from given natural language problem descriptions. It is important for exploring automatic solutions to mathematical problems and improving the reasoning ability of neural networks. \n",
    "In this demo, we use the Graph4NLP library to build a GNN-based math word problem (MWP) solving model. \n",
    "\n",
    "The **Graph2Tree** model consists of:\n",
    "\n",
    "- graph construction module (e.g., node embedding based dynamic graph)\n",
    "- graph embedding module (e.g., undirected GraphSage)\n",
    "- predictoin module (e.g., tree decoder with attention and copy mechanisms)\n",
    "\n",
    "As shown in the picture below, we firstly construct graph input from problem description by syntactic parsing (CoreNLP) and then represent the output equation with a hierarchical structure (Node ``N`` stands for non-terminal node).\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"./imgs/g2t.png\" width=\"600\" class=\"center\" alt=\"graph2tree_mwp\"/>\n",
    "    <br/>\n",
    "</p>\n",
    "\n",
    "We will use the built-in Graph2Tree model APIs to build the model, and evaluate it on the Mawps dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "---\n",
    "\n",
    "Please follow the instructions [here](https://github.com/graph4ai/graph4nlp_demo#environment-setup) to set up the environment. Please also run the following commands to install extra packages used in this demo.\n",
    "```\n",
    "pip install sympy\n",
    "pip install ipywidgets\n",
    "```\n",
    "\n",
    "\n",
    "This notebook was tested on :\n",
    "\n",
    "```\n",
    "torch == 1.9.0\n",
    "torchtext == 0.10.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T13:51:01.626460Z",
     "start_time": "2021-07-22T13:51:01.615750Z"
    }
   },
   "source": [
    "## Load the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T10:13:55.123979Z",
     "start_time": "2021-07-27T10:13:55.092616Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 20,\n",
      " 'beam_size': 4,\n",
      " 'checkpoint_save_path': './checkpoint_save',\n",
      " 'dataset_yaml': './config.yaml',\n",
      " 'decoder_args': {'rnn_decoder_private': {'max_decoder_step': 35,\n",
      "                                          'max_tree_depth': 8,\n",
      "                                          'use_input_feed': True,\n",
      "                                          'use_sibling': False},\n",
      "                  'rnn_decoder_share': {'attention_type': 'uniform',\n",
      "                                        'dropout': 0.3,\n",
      "                                        'fuse_strategy': 'concatenate',\n",
      "                                        'graph_pooling_strategy': None,\n",
      "                                        'hidden_size': 300,\n",
      "                                        'input_size': 300,\n",
      "                                        'rnn_emb_input_size': 300,\n",
      "                                        'rnn_type': 'lstm',\n",
      "                                        'teacher_forcing_rate': 1.0,\n",
      "                                        'use_copy': True,\n",
      "                                        'use_coverage': False}},\n",
      " 'decoder_name': 'stdtree',\n",
      " 'gpuid': -1,\n",
      " 'grad_clip': 5,\n",
      " 'graph_construction_args': {'graph_construction_private': {'as_node': False,\n",
      "                                                            'edge_strategy': 'homogeneous',\n",
      "                                                            'merge_strategy': 'tailhead',\n",
      "                                                            'sequential_link': True},\n",
      "                             'graph_construction_share': {'graph_name': 'dependency',\n",
      "                                                          'graph_type': 'dependency',\n",
      "                                                          'port': 9000,\n",
      "                                                          'root_dir': './data',\n",
      "                                                          'share_vocab': True,\n",
      "                                                          'thread_number': 4,\n",
      "                                                          'timeout': 15000,\n",
      "                                                          'topology_subdir': 'DependencyGraph'},\n",
      "                             'node_embedding': {'connectivity_ratio': 0.05,\n",
      "                                                'embedding_style': {'bert_lower_case': None,\n",
      "                                                                    'bert_model_name': None,\n",
      "                                                                    'emb_strategy': 'w2v_bilstm',\n",
      "                                                                    'num_rnn_layers': 1,\n",
      "                                                                    'single_token_item': True},\n",
      "                                                'epsilon_neigh': 0.5,\n",
      "                                                'fix_bert_emb': False,\n",
      "                                                'fix_word_emb': False,\n",
      "                                                'hidden_size': 300,\n",
      "                                                'input_size': 300,\n",
      "                                                'num_heads': 1,\n",
      "                                                'rnn_dropout': 0.1,\n",
      "                                                'sim_metric_type': 'weighted_cosine',\n",
      "                                                'smoothness_ratio': 0.1,\n",
      "                                                'sparsity_ratio': 0.1,\n",
      "                                                'top_k_neigh': None,\n",
      "                                                'word_dropout': 0.1}},\n",
      " 'graph_construction_name': 'dependency',\n",
      " 'graph_embedding_args': {'graph_embedding_private': {'activation': 'relu',\n",
      "                                                      'aggregator_type': 'lstm',\n",
      "                                                      'bias': True,\n",
      "                                                      'norm': None,\n",
      "                                                      'use_edge_weight': False},\n",
      "                          'graph_embedding_share': {'attn_drop': 0.0,\n",
      "                                                    'direction_option': 'undirected',\n",
      "                                                    'feat_drop': 0.0,\n",
      "                                                    'hidden_size': 300,\n",
      "                                                    'input_size': 300,\n",
      "                                                    'num_layers': 1,\n",
      "                                                    'output_size': 300}},\n",
      " 'graph_embedding_name': 'graphsage',\n",
      " 'graph_initialization_args': {'embedding_style': {'bert_lower_case': None,\n",
      "                                                   'bert_model_name': None,\n",
      "                                                   'emb_strategy': 'w2v_bilstm',\n",
      "                                                   'num_rnn_layers': 1,\n",
      "                                                   'single_token_item': True},\n",
      "                               'fix_bert_emb': False,\n",
      "                               'fix_word_emb': False,\n",
      "                               'hidden_size': 300,\n",
      "                               'input_size': 300,\n",
      "                               'rnn_dropout': 0.0,\n",
      "                               'word_dropout': 0.0},\n",
      " 'graph_type': 'static',\n",
      " 'init_weight': 0.08,\n",
      " 'learning_rate': 0.001,\n",
      " 'max_epochs': 20,\n",
      " 'min_freq': 1,\n",
      " 'pretrained_word_emb_cache_dir': '.vector_cache',\n",
      " 'pretrained_word_emb_name': None,\n",
      " 'pretrained_word_emb_url': None,\n",
      " 'seed': 123,\n",
      " 'share_vocab': True,\n",
      " 'weight_decay': 0}\n"
     ]
    }
   ],
   "source": [
    "from graph4nlp.pytorch.modules.config import get_basic_args\n",
    "from graph4nlp.pytorch.modules.utils.config_utils import update_values, get_yaml_config\n",
    "\n",
    "def get_args():\n",
    "    config = {'dataset_yaml': \"./config_v2.yaml\",\n",
    "              'learning_rate': 1e-3,\n",
    "              'gpuid': -1,\n",
    "              'seed': 123, \n",
    "              'init_weight': 0.08,\n",
    "              'graph_type': 'static',\n",
    "              'weight_decay': 0, \n",
    "              'max_epochs': 20, \n",
    "              'min_freq': 1,\n",
    "              'grad_clip': 5,\n",
    "              'batch_size': 20,\n",
    "              'share_vocab': True,\n",
    "              'pretrained_word_emb_name': None,\n",
    "              'pretrained_word_emb_url': None,\n",
    "              'pretrained_word_emb_cache_dir': \".vector_cache\",\n",
    "              'checkpoint_save_path': \"./checkpoint_save\",\n",
    "              'beam_size': 4\n",
    "              }\n",
    "    our_args = get_yaml_config(config['dataset_yaml'])\n",
    "    template = get_basic_args(graph_construction_name=our_args[\"graph_construction_name\"],\n",
    "                              graph_embedding_name=our_args[\"graph_embedding_name\"],\n",
    "                              decoder_name=our_args[\"decoder_name\"])\n",
    "    update_values(to_args=template, from_args_list=[our_args, config])\n",
    "    return template\n",
    "\n",
    "# show our config\n",
    "cfg_g2t = get_args()\n",
    "from pprint import pprint\n",
    "pprint(cfg_g2t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T10:13:55.452276Z",
     "start_time": "2021-07-27T10:13:55.364294Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from graph4nlp.pytorch.datasets.mawps import MawpsDatasetForTree\n",
    "from graph4nlp.pytorch.models.graph2tree import Graph2Tree\n",
    "from graph4nlp.pytorch.modules.utils.tree_utils import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T10:13:55.669860Z",
     "start_time": "2021-07-27T10:13:55.640456Z"
    }
   },
   "outputs": [],
   "source": [
    "class Mawps:\n",
    "    def __init__(self, opt=None):\n",
    "        super(Mawps, self).__init__()\n",
    "        self.opt = opt\n",
    "\n",
    "        seed = self.opt[\"seed\"]\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        if self.opt[\"gpuid\"] == -1:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "        else:\n",
    "            self.device = torch.device(\"cuda:{}\".format(self.opt[\"gpuid\"]))\n",
    "\n",
    "        self.use_copy = self.opt[\"decoder_args\"][\"rnn_decoder_share\"][\"use_copy\"]\n",
    "        self.use_share_vocab = self.opt[\"graph_construction_args\"][\"graph_construction_share\"][\n",
    "            \"share_vocab\"\n",
    "        ]\n",
    "        self.data_dir = self.opt[\"graph_construction_args\"][\"graph_construction_share\"][\"root_dir\"]\n",
    "\n",
    "        self._build_dataloader()\n",
    "        self._build_model()\n",
    "        self._build_optimizer()\n",
    "\n",
    "    def _build_dataloader(self):\n",
    "        para_dic = {\n",
    "            \"root_dir\": self.data_dir,\n",
    "            \"word_emb_size\": self.opt[\"graph_initialization_args\"][\"input_size\"],\n",
    "            \"topology_subdir\": self.opt[\"graph_construction_args\"][\"graph_construction_share\"][\n",
    "                \"topology_subdir\"\n",
    "            ],\n",
    "            \"edge_strategy\": self.opt[\"graph_construction_args\"][\"graph_construction_private\"][\n",
    "                \"edge_strategy\"\n",
    "            ],\n",
    "            \"graph_name\": self.opt[\"graph_construction_args\"][\"graph_construction_share\"][\n",
    "                \"graph_name\"\n",
    "            ],\n",
    "            \"share_vocab\": self.use_share_vocab,\n",
    "            \"enc_emb_size\": self.opt[\"graph_initialization_args\"][\"input_size\"],\n",
    "            \"dec_emb_size\": self.opt[\"decoder_args\"][\"rnn_decoder_share\"][\"input_size\"],\n",
    "            \"dynamic_init_graph_name\": self.opt[\"graph_construction_args\"][\n",
    "                \"graph_construction_private\"\n",
    "            ].get(\"dynamic_init_graph_name\", None),\n",
    "            \"min_word_vocab_freq\": self.opt[\"min_freq\"],\n",
    "            \"pretrained_word_emb_name\": self.opt[\"pretrained_word_emb_name\"],\n",
    "            \"pretrained_word_emb_url\": self.opt[\"pretrained_word_emb_url\"],\n",
    "            \"pretrained_word_emb_cache_dir\": self.opt[\"pretrained_word_emb_cache_dir\"],\n",
    "        }\n",
    "\n",
    "        dataset = MawpsDatasetForTree(**para_dic)\n",
    "\n",
    "        self.train_data_loader = DataLoader(\n",
    "            dataset.train,\n",
    "            batch_size=self.opt[\"batch_size\"],\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            collate_fn=dataset.collate_fn,\n",
    "        )\n",
    "        self.test_data_loader = DataLoader(\n",
    "            dataset.test, batch_size=1, shuffle=False, num_workers=0, collate_fn=dataset.collate_fn\n",
    "        )\n",
    "        self.valid_data_loader = DataLoader(\n",
    "            dataset.val, batch_size=1, shuffle=False, num_workers=0, collate_fn=dataset.collate_fn\n",
    "        )\n",
    "        self.vocab_model = dataset.vocab_model\n",
    "        self.src_vocab = self.vocab_model.in_word_vocab\n",
    "        self.tgt_vocab = self.vocab_model.out_word_vocab\n",
    "        self.share_vocab = self.vocab_model.share_vocab if self.use_share_vocab else None\n",
    "\n",
    "    def _build_model(self):\n",
    "        \"\"\"For encoder-decoder\"\"\"\n",
    "        self.model = Graph2Tree.from_args(self.opt, vocab_model=self.vocab_model)\n",
    "        self.model.init(self.opt[\"init_weight\"])\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def _build_optimizer(self):\n",
    "        optim_state = {\n",
    "            \"learningRate\": self.opt[\"learning_rate\"],\n",
    "            \"weight_decay\": self.opt[\"weight_decay\"],\n",
    "        }\n",
    "        parameters = [p for p in self.model.parameters() if p.requires_grad]\n",
    "        self.optimizer = optim.Adam(\n",
    "            parameters, lr=optim_state[\"learningRate\"], weight_decay=optim_state[\"weight_decay\"]\n",
    "        )\n",
    "\n",
    "    def prepare_ext_vocab(self, batch_graph, src_vocab):\n",
    "        oov_dict = copy.deepcopy(src_vocab)\n",
    "        token_matrix = []\n",
    "        for n in batch_graph.node_attributes:\n",
    "            node_token = n[\"token\"]\n",
    "            if (n.get(\"type\") is None or n.get(\"type\") == 0) and oov_dict.get_symbol_idx(\n",
    "                node_token\n",
    "            ) == oov_dict.get_symbol_idx(oov_dict.unk_token):\n",
    "                oov_dict.add_symbol(node_token)\n",
    "            token_matrix.append(oov_dict.get_symbol_idx(node_token))\n",
    "        batch_graph.node_features[\"token_id_oov\"] = torch.tensor(token_matrix, dtype=torch.long).to(\n",
    "            self.device\n",
    "        )\n",
    "        return oov_dict\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        loss_to_print = 0\n",
    "        num_batch = len(self.train_data_loader)\n",
    "        for _, data in tqdm(\n",
    "            enumerate(self.train_data_loader),\n",
    "            desc=f\"Epoch {epoch:02d}\",\n",
    "            total=len(self.train_data_loader),\n",
    "        ):\n",
    "            batch_graph, batch_tree_list, batch_original_tree_list = (\n",
    "                data[\"graph_data\"],\n",
    "                data[\"dec_tree_batch\"],\n",
    "                data[\"original_dec_tree_batch\"],\n",
    "            )\n",
    "            batch_graph = batch_graph.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            oov_dict = (\n",
    "                self.prepare_ext_vocab(batch_graph, self.src_vocab) if self.use_copy else None\n",
    "            )\n",
    "\n",
    "            if self.use_copy:\n",
    "                batch_tree_list_refined = []\n",
    "                for item in batch_original_tree_list:\n",
    "                    tgt_list = oov_dict.get_symbol_idx_for_list(item.strip().split())\n",
    "                    tgt_tree = Tree.convert_to_tree(tgt_list, 0, len(tgt_list), oov_dict)\n",
    "                    batch_tree_list_refined.append(tgt_tree)\n",
    "            loss = self.model(\n",
    "                batch_graph,\n",
    "                batch_tree_list_refined if self.use_copy else batch_tree_list,\n",
    "                oov_dict=oov_dict,\n",
    "            )\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_value_(self.model.parameters(), self.opt[\"grad_clip\"])\n",
    "            self.optimizer.step()\n",
    "            loss_to_print += loss\n",
    "        return loss_to_print / num_batch\n",
    "\n",
    "    def train(self):\n",
    "        best_acc = (-1, -1)\n",
    "        best_model = None\n",
    "\n",
    "        print(\"-------------\\nStarting training.\")\n",
    "        for epoch in range(1, self.opt[\"max_epochs\"] + 1):\n",
    "            self.model.train()\n",
    "            loss_to_print = self.train_epoch(epoch)\n",
    "            print(\"epochs = {}, train_loss = {:.3f}\".format(epoch, loss_to_print))\n",
    "            if epoch > 20 and epoch % 10 == 0:\n",
    "                test_acc = self.eval(self.model, mode=\"test\")\n",
    "                val_acc = self.eval(self.model, mode=\"val\")\n",
    "                if val_acc > best_acc[1]:\n",
    "                    best_acc = (test_acc, val_acc)\n",
    "                    best_model = self.model\n",
    "        print(\"Best Acc: {:.3f}\\n\".format(best_acc[0]))\n",
    "        best_model.save_checkpoint(self.opt[\"checkpoint_save_path\"], \"best.pt\")\n",
    "        return best_acc\n",
    "\n",
    "    def eval(self, model, mode=\"val\"):\n",
    "        from evaluation import compute_tree_accuracy\n",
    "\n",
    "        model.eval()\n",
    "        reference_list = []\n",
    "        candidate_list = []\n",
    "        data_loader = self.test_data_loader if mode == \"test\" else self.valid_data_loader\n",
    "        for data in tqdm(data_loader, desc=\"Eval: \"):\n",
    "            eval_input_graph, _, batch_original_tree_list = (\n",
    "                data[\"graph_data\"],\n",
    "                data[\"dec_tree_batch\"],\n",
    "                data[\"original_dec_tree_batch\"],\n",
    "            )\n",
    "            eval_input_graph = eval_input_graph.to(self.device)\n",
    "            oov_dict = self.prepare_ext_vocab(eval_input_graph, self.src_vocab)\n",
    "\n",
    "            if self.use_copy:\n",
    "                assert len(batch_original_tree_list) == 1\n",
    "                reference = oov_dict.get_symbol_idx_for_list(batch_original_tree_list[0].split())\n",
    "                eval_vocab = oov_dict\n",
    "            else:\n",
    "                assert len(batch_original_tree_list) == 1\n",
    "                reference = model.tgt_vocab.get_symbol_idx_for_list(\n",
    "                    batch_original_tree_list[0].split()\n",
    "                )\n",
    "                eval_vocab = self.tgt_vocab\n",
    "\n",
    "            candidate = model.translate(\n",
    "                eval_input_graph,\n",
    "                oov_dict=oov_dict,\n",
    "                use_beam_search=True,\n",
    "                beam_size=self.opt[\"beam_size\"],\n",
    "            )\n",
    "\n",
    "            candidate = [int(c) for c in candidate]\n",
    "            num_left_paren = sum(1 for c in candidate if eval_vocab.idx2symbol[int(c)] == \"(\")\n",
    "            num_right_paren = sum(1 for c in candidate if eval_vocab.idx2symbol[int(c)] == \")\")\n",
    "            diff = num_left_paren - num_right_paren\n",
    "            if diff > 0:\n",
    "                for _ in range(diff):\n",
    "                    candidate.append(self.test_data_loader.tgt_vocab.symbol2idx[\")\"])\n",
    "            elif diff < 0:\n",
    "                candidate = candidate[:diff]\n",
    "            # ref_str = convert_to_string(reference, eval_vocab)\n",
    "            # cand_str = convert_to_string(candidate, eval_vocab)\n",
    "\n",
    "            reference_list.append(reference)\n",
    "            candidate_list.append(candidate)\n",
    "        eval_acc = compute_tree_accuracy(candidate_list, reference_list, eval_vocab)\n",
    "        print(\"{} accuracy = {:.3f}\\n\".format(mode, eval_acc))\n",
    "        return eval_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T10:13:58.783006Z",
     "start_time": "2021-07-27T10:13:57.875582Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hugo/opt/anaconda3/envs/graph4nlp_0.5.5/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "a = Mawps(cfg_g2t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T10:14:07.766389Z",
     "start_time": "2021-07-27T10:13:59.534775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Starting training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01:   0%|                                                                        | 0/94 [00:00<?, ?it/s]/Users/hugo/opt/anaconda3/envs/graph4nlp_0.5.5/lib/python3.8/site-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/Users/hugo/opt/anaconda3/envs/graph4nlp_0.5.5/lib/python3.8/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "Epoch 01: 100%|███████████████████████████████████████████████████████████████| 94/94 [02:05<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 1, train_loss = 24.486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02: 100%|███████████████████████████████████████████████████████████████| 94/94 [02:09<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 2, train_loss = 18.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03: 100%|███████████████████████████████████████████████████████████████| 94/94 [02:18<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 3, train_loss = 15.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04: 100%|███████████████████████████████████████████████████████████████| 94/94 [02:28<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 4, train_loss = 14.517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05: 100%|███████████████████████████████████████████████████████████████| 94/94 [02:21<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 5, train_loss = 13.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06: 100%|███████████████████████████████████████████████████████████████| 94/94 [02:20<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 6, train_loss = 12.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 07: 100%|███████████████████████████████████████████████████████████████| 94/94 [02:16<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 7, train_loss = 11.582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 08: 100%|███████████████████████████████████████████████████████████████| 94/94 [02:13<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 8, train_loss = 10.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 09: 100%|███████████████████████████████████████████████████████████████| 94/94 [02:05<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 9, train_loss = 10.260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|███████████████████████████████████████████████████████████████| 94/94 [02:42<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 10, train_loss = 10.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|███████████████████████████████████████████████████████████████| 94/94 [01:56<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 11, train_loss = 9.653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|███████████████████████████████████████████████████████████████| 94/94 [01:51<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 12, train_loss = 9.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|███████████████████████████████████████████████████████████████| 94/94 [01:54<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 13, train_loss = 8.904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|███████████████████████████████████████████████████████████████| 94/94 [01:37<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 14, train_loss = 8.665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|███████████████████████████████████████████████████████████████| 94/94 [01:26<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 15, train_loss = 8.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|███████████████████████████████████████████████████████████████| 94/94 [01:26<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 16, train_loss = 8.302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|███████████████████████████████████████████████████████████████| 94/94 [01:25<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 17, train_loss = 8.058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|███████████████████████████████████████████████████████████████| 94/94 [01:29<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 18, train_loss = 7.800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|███████████████████████████████████████████████████████████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 19, train_loss = 7.555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|███████████████████████████████████████████████████████████████| 94/94 [01:23<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs = 20, train_loss = 7.452\n",
      "Best Acc: -1.000\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'save_checkpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_acc \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mMawps.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m             best_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Acc: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(best_acc[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m--> 154\u001b[0m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_checkpoint\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint_save_path\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_acc\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'save_checkpoint'"
     ]
    }
   ],
   "source": [
    "best_acc = a.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53b113626f4385b7a52334a3b11ec5d9307ad80c73f59f759f44504bc95f0ff2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
