{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b01c06a",
   "metadata": {},
   "source": [
    "# KDD'21 DLG4NLP Tutorial Demo: Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e3e7e",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132dd151",
   "metadata": {},
   "source": [
    "In this tutorial demo, we will use the Graph4NLP library to build a GNN-based text classification model. The model consists of \n",
    "- graph construction module (e.g., dependency based static graph)\n",
    "- graph embedding module (e.g., Bi-Fuse GraphSAGE)\n",
    "- predictoin module (e.g., graph pooling + MLP classifier)\n",
    "\n",
    "We will use the built-in module APIs to build the model, and evaluate it on the TREC dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b3c0d5",
   "metadata": {},
   "source": [
    "### Environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b946a75",
   "metadata": {},
   "source": [
    "Please follow the instructions [here](https://github.com/graph4ai/graph4nlp_demo#environment-setup) to set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd5f5762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "dlopen(/Users/hugo/opt/anaconda3/envs/graph4nlp_demo_202108/lib/python3.7/site-packages/torchtext/_torchtext.so, 6): Symbol not found: __ZNK3c104Type14isSubtypeOfExtENSt3__110shared_ptrIS0_EEPNS1_13basic_ostreamIcNS1_11char_traitsIcEEEE\n  Referenced from: /Users/hugo/opt/anaconda3/envs/graph4nlp_demo_202108/lib/python3.7/site-packages/torchtext/_torchtext.so\n  Expected in: /Users/hugo/opt/anaconda3/envs/graph4nlp_demo_202108/lib/python3.7/site-packages/torch/lib/libtorch_cpu.dylib\n in /Users/hugo/opt/anaconda3/envs/graph4nlp_demo_202108/lib/python3.7/site-packages/torchtext/_torchtext.so",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p_/9t59hwtx3652g7f6w6550q540000gn/T/ipykernel_70461/3174074706.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgraph4nlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrecDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgraph4nlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_construction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgraph4nlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_construction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_construction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordEmbedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/graph4nlp_demo_202108/lib/python3.7/site-packages/graph4nlp-0.4.0-py3.7.egg/graph4nlp/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlog_level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_construction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/graph4nlp_demo_202108/lib/python3.7/site-packages/graph4nlp-0.4.0-py3.7.egg/graph4nlp/pytorch/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/graph4nlp_demo_202108/lib/python3.7/site-packages/graph4nlp-0.4.0-py3.7.egg/graph4nlp/pytorch/data/dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgraph4nlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_2d_vals_no_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_construction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphConstructionBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_construction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstituency_graph_construction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConstituencyBasedGraphConstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_construction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdependency_graph_construction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDependencyBasedGraphConstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/graph4nlp_demo_202108/lib/python3.7/site-packages/graph4nlp-0.4.0-py3.7.egg/graph4nlp/pytorch/modules/graph_construction/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdependency_graph_construction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDependencyBasedGraphConstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconstituency_graph_construction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConstituencyBasedGraphConstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mie_graph_construction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIEBasedGraphConstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnode_embedding_based_graph_construction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNodeEmbeddingBasedGraphConstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnode_embedding_based_refined_graph_construction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNodeEmbeddingBasedRefinedGraphConstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/graph4nlp_demo_202108/lib/python3.7/site-packages/graph4nlp-0.4.0-py3.7.egg/graph4nlp/pytorch/modules/graph_construction/dependency_graph_construction.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstanfordcorenlp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStanfordCoreNLP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStaticGraphConstructionBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/graph4nlp_demo_202108/lib/python3.7/site-packages/graph4nlp-0.4.0-py3.7.egg/graph4nlp/pytorch/modules/graph_construction/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0membedding_construction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEmbeddingConstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mINF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnormalize_adj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_mx_to_torch_sparse_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/graph4nlp_demo_202108/lib/python3.7/site-packages/graph4nlp-0.4.0-py3.7.egg/graph4nlp/pytorch/modules/graph_construction/embedding_construction.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_4d_vals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/graph4nlp_demo_202108/lib/python3.7/site-packages/graph4nlp-0.4.0-py3.7.egg/graph4nlp/pytorch/modules/utils/vocab_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGloVe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/graph4nlp_demo_202108/lib/python3.7/site-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0m_init_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/graph4nlp_demo_202108/lib/python3.7/site-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mext_specs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torchtext C++ Extension is not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext_specs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext_specs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/graph4nlp_demo_202108/lib/python3.7/site-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/graph4nlp_demo_202108/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/Users/hugo/opt/anaconda3/envs/graph4nlp_demo_202108/lib/python3.7/site-packages/torchtext/_torchtext.so, 6): Symbol not found: __ZNK3c104Type14isSubtypeOfExtENSt3__110shared_ptrIS0_EEPNS1_13basic_ostreamIcNS1_11char_traitsIcEEEE\n  Referenced from: /Users/hugo/opt/anaconda3/envs/graph4nlp_demo_202108/lib/python3.7/site-packages/torchtext/_torchtext.so\n  Expected in: /Users/hugo/opt/anaconda3/envs/graph4nlp_demo_202108/lib/python3.7/site-packages/torch/lib/libtorch_cpu.dylib\n in /Users/hugo/opt/anaconda3/envs/graph4nlp_demo_202108/lib/python3.7/site-packages/torchtext/_torchtext.so"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import yaml\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from graph4nlp.pytorch.datasets.trec import TrecDataset\n",
    "from graph4nlp.pytorch.modules.graph_construction import *\n",
    "from graph4nlp.pytorch.modules.graph_construction.embedding_construction import WordEmbedding\n",
    "from graph4nlp.pytorch.modules.graph_embedding import *\n",
    "from graph4nlp.pytorch.modules.prediction.classification.graph_classification import FeedForwardNN\n",
    "from graph4nlp.pytorch.modules.evaluation.base import EvaluationMetricBase\n",
    "from graph4nlp.pytorch.modules.evaluation.accuracy import Accuracy\n",
    "from graph4nlp.pytorch.modules.utils.generic_utils import EarlyStopping\n",
    "from graph4nlp.pytorch.modules.loss.general_loss import GeneralLoss\n",
    "from graph4nlp.pytorch.modules.utils.logger import Logger\n",
    "from graph4nlp.pytorch.modules.utils import constants as Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824bee58",
   "metadata": {},
   "source": [
    "### Build the text classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99827b27",
   "metadata": {},
   "source": [
    "Let's first build the GNN-based text classifier which contains three major components including graph construction module, graph embedding module and graph prediction module. \n",
    "\n",
    "For graph construction module, the Graph4NLP library provides built-in APIs to support both static graph construction methods (e.g., `dependency graph`, `constituency graph`, `IE graph`) and dynamic graph construction methods (e.g., `node embedding based graph`, `node embedding based refined graph`). When calling the graph construction API, users should also specify the `embedding style` (e.g., word2vec, BiLSTM, BERT) to initalize the node/edge embeddings. Both single-token and multi-token node/edge graphs are supported.\n",
    "\n",
    "For graph embedding module, the Graph4NLP library provides builti-in APIs to support both `undirectional` and `bidirectinal` versions for common GNNs such as `GCN`, `GraphSAGE`, `GAT` and `GGNN`. \n",
    "\n",
    "For graph prediction module, the Graph4NLP library provides a high-level graph classification prediction module which consists of a graph pooling component (e.g., average pooling, max pooling) and a multilayer perceptron (MLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b55bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, vocab, label_model, config):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.config = config\n",
    "        self.vocab = vocab\n",
    "        self.label_model = label_model\n",
    "        \n",
    "        # Specify embedding style to initialize node/edge embeddings\n",
    "        embedding_style = {'single_token_item': True if config['graph_type'] != 'ie' else False,\n",
    "                            'emb_strategy': config.get('emb_strategy', 'w2v_bilstm'),\n",
    "                            'num_rnn_layers': 1,\n",
    "                            'bert_model_name': config.get('bert_model_name', 'bert-base-uncased'),\n",
    "                            'bert_lower_case': True\n",
    "                           }\n",
    "\n",
    "        assert not (config['graph_type'] in ('node_emb', 'node_emb_refined') and config['gnn'] == 'gat'), \\\n",
    "                                'dynamic graph construction does not support GAT'\n",
    "\n",
    "        use_edge_weight = False\n",
    "        \n",
    "        \n",
    "        # Set up graph construction module\n",
    "        if config['graph_type'] == 'dependency':\n",
    "            self.graph_topology = DependencyBasedGraphConstruction(\n",
    "                                   embedding_style=embedding_style,\n",
    "                                   vocab=vocab.in_word_vocab,\n",
    "                                   hidden_size=config['num_hidden'],\n",
    "                                   word_dropout=config['word_dropout'],\n",
    "                                   rnn_dropout=config['rnn_dropout'],\n",
    "                                   fix_word_emb=not config['no_fix_word_emb'],\n",
    "                                   fix_bert_emb=not config.get('no_fix_bert_emb', False))\n",
    "        elif config['graph_type'] == 'constituency':\n",
    "            self.graph_topology = ConstituencyBasedGraphConstruction(\n",
    "                                   embedding_style=embedding_style,\n",
    "                                   vocab=vocab.in_word_vocab,\n",
    "                                   hidden_size=config['num_hidden'],\n",
    "                                   word_dropout=config['word_dropout'],\n",
    "                                   rnn_dropout=config['rnn_dropout'],\n",
    "                                   fix_word_emb=not config['no_fix_word_emb'],\n",
    "                                   fix_bert_emb=not config.get('no_fix_bert_emb', False))\n",
    "        elif config['graph_type'] == 'ie':\n",
    "            self.graph_topology = IEBasedGraphConstruction(\n",
    "                                   embedding_style=embedding_style,\n",
    "                                   vocab=vocab.in_word_vocab,\n",
    "                                   hidden_size=config['num_hidden'],\n",
    "                                   word_dropout=config['word_dropout'],\n",
    "                                   rnn_dropout=config['rnn_dropout'],\n",
    "                                   fix_word_emb=not config['no_fix_word_emb'],\n",
    "                                   fix_bert_emb=not config.get('no_fix_bert_emb', False))\n",
    "        elif config['graph_type'] == 'node_emb':\n",
    "            self.graph_topology = NodeEmbeddingBasedGraphConstruction(\n",
    "                                   vocab.in_word_vocab,\n",
    "                                   embedding_style,\n",
    "                                   sim_metric_type=config['gl_metric_type'],\n",
    "                                   num_heads=config['gl_num_heads'],\n",
    "                                   top_k_neigh=config['gl_top_k'],\n",
    "                                   epsilon_neigh=config['gl_epsilon'],\n",
    "                                   smoothness_ratio=config['gl_smoothness_ratio'],\n",
    "                                   connectivity_ratio=config['gl_connectivity_ratio'],\n",
    "                                   sparsity_ratio=config['gl_sparsity_ratio'],\n",
    "                                   input_size=config['num_hidden'],\n",
    "                                   hidden_size=config['gl_num_hidden'],\n",
    "                                   fix_word_emb=not config['no_fix_word_emb'],\n",
    "                                   fix_bert_emb=not config.get('no_fix_bert_emb', False),\n",
    "                                   word_dropout=config['word_dropout'],\n",
    "                                   rnn_dropout=config['rnn_dropout'])\n",
    "            use_edge_weight = True\n",
    "        elif config['graph_type'] == 'node_emb_refined':\n",
    "            self.graph_topology = NodeEmbeddingBasedRefinedGraphConstruction(\n",
    "                                    vocab.in_word_vocab,\n",
    "                                    embedding_style,\n",
    "                                    config['init_adj_alpha'],\n",
    "                                    sim_metric_type=config['gl_metric_type'],\n",
    "                                    num_heads=config['gl_num_heads'],\n",
    "                                    top_k_neigh=config['gl_top_k'],\n",
    "                                    epsilon_neigh=config['gl_epsilon'],\n",
    "                                    smoothness_ratio=config['gl_smoothness_ratio'],\n",
    "                                    connectivity_ratio=config['gl_connectivity_ratio'],\n",
    "                                    sparsity_ratio=config['gl_sparsity_ratio'],\n",
    "                                    input_size=config['num_hidden'],\n",
    "                                    hidden_size=config['gl_num_hidden'],\n",
    "                                    fix_word_emb=not config['no_fix_word_emb'],\n",
    "                                    fix_bert_emb=not config.get('no_fix_bert_emb', False),\n",
    "                                    word_dropout=config['word_dropout'],\n",
    "                                    rnn_dropout=config['rnn_dropout'])\n",
    "            use_edge_weight = True\n",
    "        else:\n",
    "            raise RuntimeError('Unknown graph_type: {}'.format(config['graph_type']))\n",
    "\n",
    "        if 'w2v' in self.graph_topology.embedding_layer.word_emb_layers:\n",
    "            self.word_emb = self.graph_topology.embedding_layer.word_emb_layers['w2v'].word_emb_layer\n",
    "        else:\n",
    "            self.word_emb = WordEmbedding(\n",
    "                            self.vocab.in_word_vocab.embeddings.shape[0],\n",
    "                            self.vocab.in_word_vocab.embeddings.shape[1],\n",
    "                            pretrained_word_emb=self.vocab.in_word_vocab.embeddings,\n",
    "                            fix_emb=not config['no_fix_word_emb'],\n",
    "                            device=config['device']).word_emb_layer\n",
    "\n",
    "            \n",
    "        # Set up graph embedding module\n",
    "        if config['gnn'] == 'gat':\n",
    "            heads = [config['gat_num_heads']] * (config['gnn_num_layers'] - 1) + [config['gat_num_out_heads']]\n",
    "            self.gnn = GAT(config['gnn_num_layers'],\n",
    "                        config['num_hidden'],\n",
    "                        config['num_hidden'],\n",
    "                        config['num_hidden'],\n",
    "                        heads,\n",
    "                        direction_option=config['gnn_direction_option'],\n",
    "                        feat_drop=config['gnn_dropout'],\n",
    "                        attn_drop=config['gat_attn_dropout'],\n",
    "                        negative_slope=config['gat_negative_slope'],\n",
    "                        residual=config['gat_residual'],\n",
    "                        activation=F.elu)\n",
    "        elif config['gnn'] == 'graphsage':\n",
    "            self.gnn = GraphSAGE(config['gnn_num_layers'],\n",
    "                        config['num_hidden'],\n",
    "                        config['num_hidden'],\n",
    "                        config['num_hidden'],\n",
    "                        config['graphsage_aggreagte_type'],\n",
    "                        direction_option=config['gnn_direction_option'],\n",
    "                        feat_drop=config['gnn_dropout'],\n",
    "                        bias=True,\n",
    "                        norm=None,\n",
    "                        activation=F.relu,\n",
    "                        use_edge_weight=use_edge_weight)\n",
    "        elif config['gnn'] == 'ggnn':\n",
    "            self.gnn = GGNN(config['gnn_num_layers'],\n",
    "                        config['num_hidden'],\n",
    "                        config['num_hidden'],\n",
    "                        config['num_hidden'],\n",
    "                        feat_drop=config['gnn_dropout'],\n",
    "                        direction_option=config['gnn_direction_option'],\n",
    "                        bias=True,\n",
    "                        use_edge_weight=use_edge_weight)\n",
    "        else:\n",
    "            raise RuntimeError('Unknown gnn type: {}'.format(config['gnn']))\n",
    "\n",
    "            \n",
    "        # Set up graph prediction module\n",
    "        self.clf = FeedForwardNN(2 * config['num_hidden'] \\\n",
    "                        if config['gnn_direction_option'] == 'bi_sep' \\\n",
    "                        else config['num_hidden'],\n",
    "                        config['num_classes'],\n",
    "                        [config['num_hidden']],\n",
    "                        graph_pool_type=config['graph_pooling'],\n",
    "                        dim=config['num_hidden'],\n",
    "                        use_linear_proj=config['max_pool_linear_proj'])\n",
    "\n",
    "        self.loss = GeneralLoss('CrossEntropy')\n",
    "\n",
    "\n",
    "    def forward(self, graph_list, tgt=None, require_loss=True):\n",
    "        # build graph topology\n",
    "        batch_gd = self.graph_topology(graph_list)\n",
    "\n",
    "        # run GNN encoder\n",
    "        self.gnn(batch_gd)\n",
    "\n",
    "        # run graph classifier\n",
    "        self.clf(batch_gd)\n",
    "        logits = batch_gd.graph_attributes['logits']\n",
    "\n",
    "        if require_loss:\n",
    "            loss = self.loss(logits, tgt)\n",
    "            return logits, loss\n",
    "        else:\n",
    "            return logits\n",
    "    \n",
    "    @classmethod\n",
    "    def load_checkpoint(cls, model_path):\n",
    "        return torch.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4a64e2",
   "metadata": {},
   "source": [
    "### Build the model handler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b8ff8b",
   "metadata": {},
   "source": [
    "Next, let's build a model handler which will do a bunch of things including setting up dataloader, model, optimizer, evaluation metrics, train/val/test loops, and so on.\n",
    "\n",
    "When setting up the dataloader, users will need to call the dataset API which will preprocess the data, e.g., calling the graph construction module, building the vocabulary, tensorizing the data. Users can build their customized dataset APIs by inheriting our low-level dataset APIs. We provide low-level dataset APIs to support various scenarios (e.g., `Text2Label`, `Sequence2Labeling`, `Text2Text`, `Text2Tree`, `DoubleText2Text`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda1f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelHandler:\n",
    "    def __init__(self, config):\n",
    "        super(ModelHandler, self).__init__()\n",
    "        self.config = config\n",
    "        self.logger = Logger(self.config['out_dir'], config={k:v for k, v in self.config.items() if k != 'device'}, overwrite=True)\n",
    "        self.logger.write(self.config['out_dir'])\n",
    "        self._build_device()\n",
    "        self._build_dataloader()\n",
    "        self._build_model()\n",
    "        self._build_optimizer()\n",
    "        self._build_evaluation()\n",
    "\n",
    "    def _build_device(self):\n",
    "        if not self.config['no_cuda'] and torch.cuda.is_available():\n",
    "            print('[ Using CUDA ]')\n",
    "            self.config['device'] = torch.device('cuda' if self.config['gpu'] < 0 else 'cuda:%d' % self.config['gpu'])\n",
    "            torch.cuda.manual_seed(self.config['seed'])\n",
    "            torch.cuda.manual_seed_all(self.config['seed'])\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            cudnn.benchmark = False\n",
    "        else:\n",
    "            self.config['device'] = torch.device('cpu')\n",
    "        \n",
    "    def _build_dataloader(self):\n",
    "        dynamic_init_topology_builder = None\n",
    "        if self.config['graph_type'] == 'dependency':\n",
    "            topology_builder = DependencyBasedGraphConstruction\n",
    "            graph_type = 'static'\n",
    "            merge_strategy = 'tailhead'\n",
    "        elif self.config['graph_type'] == 'constituency':\n",
    "            topology_builder = ConstituencyBasedGraphConstruction\n",
    "            graph_type = 'static'\n",
    "            merge_strategy = 'tailhead'\n",
    "        elif self.config['graph_type'] == 'ie':\n",
    "            topology_builder = IEBasedGraphConstruction\n",
    "            graph_type = 'static'\n",
    "            merge_strategy = 'global'\n",
    "        elif self.config['graph_type'] == 'node_emb':\n",
    "            topology_builder = NodeEmbeddingBasedGraphConstruction\n",
    "            graph_type = 'dynamic'\n",
    "            merge_strategy = None\n",
    "        elif self.config['graph_type'] == 'node_emb_refined':\n",
    "            topology_builder = NodeEmbeddingBasedRefinedGraphConstruction\n",
    "            graph_type = 'dynamic'\n",
    "            merge_strategy = 'tailhead'\n",
    "\n",
    "            if self.config['init_graph_type'] == 'line':\n",
    "                dynamic_init_topology_builder = None\n",
    "            elif self.config['init_graph_type'] == 'dependency':\n",
    "                dynamic_init_topology_builder = DependencyBasedGraphConstruction\n",
    "            elif self.config['init_graph_type'] == 'constituency':\n",
    "                dynamic_init_topology_builder = ConstituencyBasedGraphConstruction\n",
    "            elif self.config['init_graph_type'] == 'ie':\n",
    "                merge_strategy = 'global'\n",
    "                dynamic_init_topology_builder = IEBasedGraphConstruction\n",
    "            else:\n",
    "                raise RuntimeError('Define your own dynamic_init_topology_builder')\n",
    "        else:\n",
    "            raise RuntimeError('Unknown graph_type: {}'.format(self.config['graph_type']))\n",
    "\n",
    "        topology_subdir = '{}_graph'.format(self.config['graph_type'])\n",
    "        if self.config['graph_type'] == 'node_emb_refined':\n",
    "            topology_subdir += '_{}'.format(self.config['init_graph_type'])\n",
    "\n",
    "            \n",
    "        # Call the TREC dataset API\n",
    "        dataset = TrecDataset(root_dir=self.config.get('root_dir', self.config['root_data_dir']),\n",
    "                              pretrained_word_emb_name=self.config.get('pretrained_word_emb_name', \"840B\"),\n",
    "                              merge_strategy=merge_strategy,\n",
    "                              seed=self.config['seed'],\n",
    "                              thread_number=4,\n",
    "                              port=9000,\n",
    "                              timeout=15000,\n",
    "                              word_emb_size=300,\n",
    "                              graph_type=graph_type,\n",
    "                              topology_builder=topology_builder,\n",
    "                              topology_subdir=topology_subdir,\n",
    "                              dynamic_graph_type=self.config['graph_type'] if \\\n",
    "                                  self.config['graph_type'] in ('node_emb', 'node_emb_refined') else None,\n",
    "                              dynamic_init_topology_builder=dynamic_init_topology_builder,\n",
    "                              dynamic_init_topology_aux_args={'dummy_param': 0})\n",
    "\n",
    "        self.train_dataloader = DataLoader(dataset.train, batch_size=self.config['batch_size'], shuffle=True,\n",
    "                                           num_workers=self.config['num_workers'],\n",
    "                                           collate_fn=dataset.collate_fn)\n",
    "        if hasattr(dataset, 'val')==False:\n",
    "            dataset.val = dataset.test\n",
    "        self.val_dataloader = DataLoader(dataset.val, batch_size=self.config['batch_size'], shuffle=False,\n",
    "                                          num_workers=self.config['num_workers'],\n",
    "                                          collate_fn=dataset.collate_fn)\n",
    "        self.test_dataloader = DataLoader(dataset.test, batch_size=self.config['batch_size'], shuffle=False,\n",
    "                                          num_workers=self.config['num_workers'],\n",
    "                                          collate_fn=dataset.collate_fn)\n",
    "        self.vocab = dataset.vocab_model\n",
    "        self.label_model = dataset.label_model\n",
    "        self.config['num_classes'] = self.label_model.num_classes\n",
    "        self.num_train = len(dataset.train)\n",
    "        self.num_val = len(dataset.val)\n",
    "        self.num_test = len(dataset.test)\n",
    "        print('Train size: {}, Val size: {}, Test size: {}'\n",
    "            .format(self.num_train, self.num_val, self.num_test))\n",
    "        self.logger.write('Train size: {}, Val size: {}, Test size: {}'\n",
    "            .format(self.num_train, self.num_val, self.num_test))\n",
    "\n",
    "    def _build_model(self):\n",
    "        self.model = TextClassifier(self.vocab, self.label_model, self.config).to(self.config['device'])\n",
    "\n",
    "    def _build_optimizer(self):\n",
    "        parameters = [p for p in self.model.parameters() if p.requires_grad]\n",
    "        self.optimizer = optim.Adam(parameters, lr=self.config['lr'])\n",
    "        self.stopper = EarlyStopping(os.path.join(self.config['out_dir'], Constants._SAVED_WEIGHTS_FILE), patience=self.config['patience'])\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, mode='max', factor=self.config['lr_reduce_factor'], \\\n",
    "            patience=self.config['lr_patience'], verbose=True)\n",
    "\n",
    "    def _build_evaluation(self):\n",
    "        self.metric = Accuracy(['accuracy'])\n",
    "\n",
    "    def train(self):\n",
    "        dur = []\n",
    "        for epoch in range(self.config['epochs']):\n",
    "            self.model.train()\n",
    "            train_loss = []\n",
    "            train_acc = []\n",
    "            t0 = time.time()\n",
    "            for i, data in enumerate(self.train_dataloader):\n",
    "                tgt = data['tgt_tensor'].to(self.config['device'])\n",
    "                data['graph_data'] = data['graph_data'].to(self.config['device'])\n",
    "                logits, loss = self.model(data['graph_data'], tgt, require_loss=True)\n",
    "\n",
    "                # add graph regularization loss if available\n",
    "                if data['graph_data'].graph_attributes.get('graph_reg', None) is not None:\n",
    "                    loss = loss + data['graph_data'].graph_attributes['graph_reg']\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "                pred = torch.max(logits, dim=-1)[1].cpu()\n",
    "                train_acc.append(self.metric.calculate_scores(ground_truth=tgt.cpu(), predict=pred.cpu(), zero_division=0)[0])\n",
    "                dur.append(time.time() - t0)\n",
    "\n",
    "            val_acc = self.evaluate(self.val_dataloader)\n",
    "            self.scheduler.step(val_acc)\n",
    "            print('Epoch: [{} / {}] | Time: {:.2f}s | Loss: {:.4f} | Train Acc: {:.4f} | Val Acc: {:.4f}'.\n",
    "              format(epoch + 1, self.config['epochs'], np.mean(dur), np.mean(train_loss), np.mean(train_acc), val_acc))\n",
    "            self.logger.write('Epoch: [{} / {}] | Time: {:.2f}s | Loss: {:.4f} | Train Acc: {:.4f} | Val Acc: {:.4f}'.\n",
    "                        format(epoch + 1, self.config['epochs'], np.mean(dur), np.mean(train_loss), np.mean(train_acc), val_acc))\n",
    "\n",
    "            if self.stopper.step(val_acc, self.model):\n",
    "                break\n",
    "\n",
    "        return self.stopper.best_score\n",
    "\n",
    "    def evaluate(self, dataloader):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred_collect = []\n",
    "            gt_collect = []\n",
    "            for i, data in enumerate(dataloader):\n",
    "                tgt = data['tgt_tensor'].to(self.config['device'])\n",
    "                data['graph_data'] = data['graph_data'].to(self.config[\"device\"])\n",
    "                logits = self.model(data['graph_data'], require_loss=False)\n",
    "                pred_collect.append(logits)\n",
    "                gt_collect.append(tgt)\n",
    "\n",
    "            pred_collect = torch.max(torch.cat(pred_collect, 0), dim=-1)[1].cpu()\n",
    "            gt_collect = torch.cat(gt_collect, 0).cpu()\n",
    "            score = self.metric.calculate_scores(ground_truth=gt_collect, predict=pred_collect, zero_division=0)[0]\n",
    "\n",
    "            return score\n",
    "\n",
    "    def test(self):\n",
    "        # restored best saved model\n",
    "        self.model = TextClassifier.load_checkpoint(self.stopper.save_model_path)\n",
    "\n",
    "        t0 = time.time()\n",
    "        acc = self.evaluate(self.test_dataloader)\n",
    "        dur = time.time() - t0\n",
    "        print('Test examples: {} | Time: {:.2f}s |  Test Acc: {:.4f}'.\n",
    "          format(self.num_test, dur, acc))\n",
    "        self.logger.write('Test examples: {} | Time: {:.2f}s |  Test Acc: {:.4f}'.\n",
    "          format(self.num_test, dur, acc))\n",
    "\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad3d820",
   "metadata": {},
   "source": [
    "### Set up the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bff971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_config(config):\n",
    "    print('**************** MODEL CONFIGURATION ****************')\n",
    "    for key in sorted(config.keys()):\n",
    "        val = config[key]\n",
    "        keystr = '{}'.format(key) + (' ' * (24 - len(key)))\n",
    "        print('{} -->   {}'.format(keystr, val))\n",
    "    print('**************** MODEL CONFIGURATION ****************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b9931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config setup\n",
    "config_file = '../config/trec/graphsage_bi_fuse_static_dependency.yaml'\n",
    "config = yaml.load(open(config_file, 'r'), Loader=yaml.FullLoader)\n",
    "print_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed47302",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5087ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model\n",
    "# import platform#, multiprocessing\n",
    "# if platform.system() == \"Darwin\": # MacOS\n",
    "#     multiprocessing.set_start_method('spawn')\n",
    "np.random.seed(config['seed'])\n",
    "torch.manual_seed(config['seed'])\n",
    "\n",
    "ts = datetime.datetime.now().timestamp()\n",
    "config['out_dir'] += '_{}'.format(ts)\n",
    "print('\\n' + config['out_dir'])\n",
    "\n",
    "runner = ModelHandler(config)\n",
    "t0 = time.time()\n",
    "\n",
    "val_acc = runner.train()\n",
    "test_acc = runner.test()\n",
    "\n",
    "runtime = time.time() - t0\n",
    "print('Total runtime: {:.2f}s'.format(runtime))\n",
    "runner.logger.write('Total runtime: {:.2f}s\\n'.format(runtime))\n",
    "runner.logger.close()\n",
    "\n",
    "print('val acc: {}, test acc: {}'.format(val_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c537b575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
